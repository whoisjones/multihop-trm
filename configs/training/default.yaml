batch_size: 128
num_steps: 50000
warmup_steps: 1000
eval_interval: 5000
log_interval: 20
learning_rate: 1e-4
max_norm: 1.0
weight_decay: 0.01
optimizer_type: adamw
scheduler_type: constant_with_warmup
mixed_precision: bf16

